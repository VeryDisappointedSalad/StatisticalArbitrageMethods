{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers(path = 'Data\\Real\\Financial\\microprocessor_stocks_2023-25.csv'):\n",
    "\n",
    "    tickers = pd.read_csv(path)\n",
    "    tickers = tickers['ticker'].unique()\n",
    "    return tickers\n",
    "\n",
    "def load_ticker(ticker,\n",
    "                include_NLP = False\n",
    "                ):\n",
    "\n",
    "    # read data and set date index\n",
    "    X = pd.read_csv(f'Data\\ParsedDataForModel\\{ticker}.csv')\n",
    "    X['date'] = X['Unnamed: 0']\n",
    "    X['date'] = pd.to_datetime(X['date'])\n",
    "    X.index = X['date']\n",
    "\n",
    "\n",
    "    # map the sentiment\n",
    "    sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "    X[f'{ticker}_sentiment'] = X[f'{ticker}_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "    # resample hourly\n",
    "    X = X[['close', f'{ticker}_score', f'{ticker}_sentiment']].resample('1h').mean()\n",
    "\n",
    "    # target variable\n",
    "    X.loc[:, 'target'] = X['close'].shift(-1)\n",
    "    X = X.dropna()\n",
    "    y = X[['target']].copy()\n",
    "\n",
    "    # additional variables\n",
    "    X.loc[:, 'FMA'] = X['close'].rolling(window = '5h').mean()\n",
    "    X.loc[:, 'SMA'] = X['close'].rolling(window = '10h').mean()\n",
    "    X = X.dropna()\n",
    "\n",
    "    if include_NLP:\n",
    "        X = X[['FMA', 'SMA', 'close', f'{ticker}_score', f'{ticker}_sentiment']]\n",
    "    else:\n",
    "        X = X[['FMA', 'SMA', 'close']]\n",
    "        \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_model(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=0.001,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds and trains an LSTM model.\n",
    "    Returns the trained model and the RMSE on the validation set.\n",
    "    \"\"\"\n",
    "    # 1) Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))  # explicit input layer\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(64, return_sequences = True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1))  # single numeric output\n",
    "\n",
    "    # 2) Compile\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    # 3) Fit\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # 4) Compute validation RMSE\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "    return model, rmse_val\n",
    "\n",
    "def gridsearch_lstm(\n",
    "    X, y,\n",
    "    train_prop=0.7, val_prop=0.15, test_prop=0.15,\n",
    "    param_grid=None, verbose = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits (X, y) into train/val/test according to train_prop, val_prop, test_prop,\n",
    "    then grid-searches an LSTM over param_grid on (train, val), \n",
    "    and returns predictions on the test set.\n",
    "\n",
    "    :param X: 2D numpy array, shape (N, num_features).\n",
    "    :param y: 1D numpy array, shape (N,).\n",
    "    :param train_prop: float, proportion for training (e.g. 0.7).\n",
    "    :param val_prop: float, proportion for validation (e.g. 0.15).\n",
    "    :param test_prop: float, proportion for test (e.g. 0.15).\n",
    "    :param param_grid: dict of lists, e.g. {\n",
    "         'dropout_rate': [0.0, 0.2],\n",
    "         'learning_rate': [0.01, 0.001],\n",
    "         'epochs': [5, 10],\n",
    "         'batch_size': [32, 64]\n",
    "      }\n",
    "\n",
    "    :return:\n",
    "      - best_model: the Keras model that had the best val RMSE\n",
    "      - test_preds: predictions of the best model on test set\n",
    "      - y_test: true target values for test set\n",
    "      - best_params: dict of hyperparams that gave the best val RMSE\n",
    "      - test_rmse: RMSE on the test set\n",
    "    \"\"\"\n",
    "    if param_grid is None:\n",
    "        # A small default param grid\n",
    "        param_grid = {\n",
    "            'dropout_rate': [0.0, 0.2],\n",
    "            'learning_rate': [0.001],\n",
    "            'epochs': [5],\n",
    "            'batch_size': [32]\n",
    "        }\n",
    "\n",
    "    n = len(X)\n",
    "    # 1) Split indices\n",
    "    train_end = int(n * train_prop)\n",
    "    val_end   = int(n * (train_prop + val_prop))  # up to but not including\n",
    "    # test is [val_end..]\n",
    "\n",
    "    # 2) Slice data\n",
    "    X_train_raw = X[:train_end]\n",
    "    y_train_raw = y[:train_end]\n",
    "\n",
    "    X_val_raw   = X[train_end:val_end]\n",
    "    y_val_raw   = y[train_end:val_end]\n",
    "\n",
    "    X_test_raw  = X[val_end:]\n",
    "    y_test      = y[val_end:]\n",
    "\n",
    "    # 3) Reshape for LSTM if you want (samples, timesteps=1, features)\n",
    "    #    i.e. each sample is 1 time-step with 'num_features' inputs\n",
    "    X_train = X_train_raw.reshape(X_train_raw.shape[0], 1, X_train_raw.shape[1])\n",
    "    X_val   = X_val_raw.reshape(X_val_raw.shape[0], 1, X_val_raw.shape[1])\n",
    "    X_test  = X_test_raw.reshape(X_test_raw.shape[0], 1, X_test_raw.shape[1])\n",
    "\n",
    "    # 4) Grid Search\n",
    "    best_rmse = float('inf')\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    # Convert param_grid dict -> list of keys & list of lists for product\n",
    "    param_keys, param_values = zip(*param_grid.items())  # e.g. (('dropout_rate','lr','epochs','batch_size'), ([0.0,0.2],[...],...))\n",
    "    for combo in product(*param_values):\n",
    "        current_params = dict(zip(param_keys, combo))\n",
    "\n",
    "        # Train model on train, measure val RMSE\n",
    "        model, rmse_val = build_and_train_model(\n",
    "            X_train, y_train_raw,\n",
    "            X_val,   y_val_raw,\n",
    "            dropout_rate=current_params.get('dropout_rate', 0.2),\n",
    "            learning_rate=current_params.get('learning_rate', 0.001),\n",
    "            epochs=current_params.get('epochs', 10),\n",
    "            batch_size=current_params.get('batch_size', 32),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "        if rmse_val < best_rmse:\n",
    "            best_rmse = rmse_val\n",
    "            best_model = model\n",
    "            best_params = current_params\n",
    "\n",
    "    # 5) Predict on test with best model\n",
    "    test_preds = best_model.predict(X_test).ravel()\n",
    "\n",
    "    return test_preds, y_test, best_params, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Walk Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self, validation_data, scaler, filepath=\"best_custom_model.keras\"):\n",
    "\n",
    "        self.validation_data = validation_data\n",
    "        self.filepath = filepath\n",
    "        self.best_score = -np.inf  # Higher is better for information ratio\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def information_ratio_metric(self, y_val, y_val_pred):\n",
    "\n",
    "        y_val = y_val.flatten()\n",
    "        y_val_pred = self.scaler.inverse_transform(y_val_pred.reshape(-1, 1)).flatten()\n",
    "        y_val = self.scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {'target' : y_val.flatten(), 'prediction' : y_val_pred}\n",
    "        )\n",
    "\n",
    "        def sign_func(x, threshold = 0):\n",
    "            if x > threshold:\n",
    "                return 1\n",
    "            elif x < -threshold:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        df['prediction'] = df['prediction'].pct_change()\n",
    "        df['target'] = df['target'].pct_change() # r_t\n",
    "        df = df.dropna()\n",
    "\n",
    "        df['prediction'] = df['prediction'].apply(sign_func) # 1 if r_t >0, -1 if r_t <0\n",
    "        df['prediction'] = df['prediction'] * df['target'] # (1 or -1 or 1) * r_t\n",
    "        aSD = np.sqrt(252) * (df['prediction'].std())\n",
    "        df['prediction'] = df['prediction'] + 1\n",
    "        df['prediction'] = df['prediction'].cumprod() # K_t -> equity curve\n",
    "\n",
    "        aRC = (df['prediction'].values[-1]) ** (252 / (len(df))) - 1\n",
    "        #print(aSD, aRC)\n",
    "        \n",
    "        return aRC/aSD\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_val_pred = self.model.predict(X_val, verbose=0).flatten()\n",
    "\n",
    "        # Compute custom metric\n",
    "        score = self.information_ratio_metric(y_val, y_val_pred)\n",
    "\n",
    "        # Save best model based on custom metric\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.model.save(self.filepath)\n",
    "            print(f\"\\nEpoch {epoch + 1}: Information Ratio improved to {score:.5f}, saving model.\\n\")\n",
    "\n",
    "def build_and_train_model(\n",
    "    \n",
    "    # Data\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "\n",
    "    # StandardScaler to transform preds into prices for inner IR optimization\n",
    "    scaler_y,\n",
    "    \n",
    "    # Grid search params\n",
    "    dropout_rate=0.2, learning_rate=0.001, epochs=10, batch_size=32,\n",
    "\n",
    "    # For comments in console\n",
    "    verbose=0\n",
    "):\n",
    "    \n",
    "    # 1) Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))  # explicit input layer\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(64, return_sequences = True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1))  # single numeric output\n",
    "\n",
    "    # 2) Compile\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    # 3) Define custom checkpoint callback\n",
    "    custom_checkpoint = CustomCheckpoint(validation_data=(X_val, y_val), scaler = scaler_y)\n",
    "\n",
    "    # 4) Train the model with the custom checkpoint\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose,\n",
    "        callbacks=[custom_checkpoint]\n",
    "    )\n",
    "\n",
    "    # 5) Load the best model (selected based on information_ratio_metric)\n",
    "    best_model = load_model(\"best_custom_model.keras\")\n",
    "\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def gridsearch_lstm_walk_forward(\n",
    "        \n",
    "    # data\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test,\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid,\n",
    "\n",
    "    # parameters\n",
    "    verbose = 1\n",
    "):\n",
    "    \n",
    "    # StandardScaler to transform the data\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train = scaler_X.fit_transform(X_train)\n",
    "    X_val = scaler_X.transform(X_val)\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "    y_val = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "    # Reshape the data  \n",
    "    #X_train, y_train = X_train.to_numpy(), y_train.to_numpy() \n",
    "    #X_val, y_val = X_val.to_numpy(), y_val.to_numpy()\n",
    "    #X_test = X_test.to_numpy()\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_val   = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "    X_test  = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "\n",
    "    # Perform gridsearch for given data and params grid\n",
    "    param_keys, param_values = zip(*param_grid.items()) \n",
    "\n",
    "    for combo in product(*param_values):\n",
    "\n",
    "        current_params = dict(zip(param_keys, combo))\n",
    "\n",
    "        # Train model on train, measure val RMSE\n",
    "        model = build_and_train_model(\n",
    "            X_train, y_train,\n",
    "            X_val,   y_val,\n",
    "            scaler_y,\n",
    "            dropout_rate=current_params.get('dropout_rate'),\n",
    "            learning_rate=current_params.get('learning_rate'),\n",
    "            epochs=current_params.get('epochs'),\n",
    "            batch_size=current_params.get('batch_size'),\n",
    "            verbose = verbose\n",
    "        )\n",
    "\n",
    "    # Predict on test with best model\n",
    "    test_preds = model.predict(X_test).ravel()\n",
    "    test_preds = scaler_y.inverse_transform(test_preds.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return test_preds\n",
    "\n",
    "def walk_forward_block_optimization(\n",
    "    X, y,\n",
    "    n_blocks = 10, \n",
    "    train_blocks = 5, val_blocks = 1, test_blocks = 1,\n",
    "    param_grid=None,\n",
    "    verbose=1\n",
    "):\n",
    "    \n",
    "    if train_blocks + val_blocks + test_blocks > n_blocks:\n",
    "        print('Incorrect number of blocks specified')\n",
    "        return 0\n",
    "    \n",
    "    n = len(X)\n",
    "    block_size = n // n_blocks  # Number of samples per block\n",
    "    all_results = []\n",
    "\n",
    "    for start_block in range(n_blocks - (train_blocks + val_blocks + test_blocks) + 1):\n",
    "\n",
    "        # Define block indices\n",
    "        train_start = start_block * block_size\n",
    "        train_end = train_start + train_blocks * block_size\n",
    "        val_end = train_end + val_blocks * block_size\n",
    "        test_end = val_end + test_blocks * block_size\n",
    "\n",
    "        # Extract rolling block window data\n",
    "        X_train, y_train = X.iloc[train_start:train_end], y.iloc[train_start:train_end]\n",
    "        X_val, y_val = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "        X_test, y_test = X.iloc[val_end:test_end], y.iloc[val_end:test_end]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Iteration {start_block+1}/{n_blocks - (train_blocks + val_blocks + test_blocks) + 1}: Train [{train_start}:{train_end}], Val [{train_end}:{val_end}], Test [{val_end}:{test_end}]\")\n",
    "\n",
    "\n",
    "        # Run gridsearch on this block-wise set\n",
    "        test_preds = gridsearch_lstm_walk_forward(\n",
    "\n",
    "            X_train, y_train,\n",
    "            X_val, y_val,\n",
    "            X_test,\n",
    "            param_grid,\n",
    "            verbose\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        segment_results = pd.DataFrame({\n",
    "            \"timestamp\": X_test.index,  # Keep correct timestamps\n",
    "            \"true_value\": y_test['target'],\n",
    "            \"predicted_value\": test_preds\n",
    "        })\n",
    "        all_results.append(segment_results)\n",
    "\n",
    "    # Concatenate results from all splits\n",
    "    final_results = pd.concat(all_results, ignore_index=True)\n",
    "    final_results.index = final_results['timestamp']\n",
    "    final_results = final_results[['true_value', 'predicted_value']]\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = get_tickers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all the results\n",
    "results = []\n",
    "\n",
    "# Iterate over all stocks\n",
    "for ticker in TICKERS:\n",
    "\n",
    "    # Load the data\n",
    "    print(f'Loading data for {ticker}...')\n",
    "    X_nlp, y_nlp = load_ticker(ticker, include_NLP = True)\n",
    "    X_base, y_base = load_ticker(ticker, include_NLP = False)\n",
    "    print(f'Finished loading data for {ticker}')\n",
    "\n",
    "    # Define hyperparam grid\n",
    "    hyperparams_grid = {\n",
    "    'dropout_rate': [0.0],\n",
    "    'learning_rate': [0.01],\n",
    "    'epochs': [5],\n",
    "    'batch_size' : [32]}\n",
    "\n",
    "    # Run the model for base scenario\n",
    "    final_results_base = walk_forward_block_optimization(\n",
    "    X = X_base,\n",
    "    y = y_base,\n",
    "    n_blocks = 15,\n",
    "    train_blocks = 10,\n",
    "    val_blocks = 1,\n",
    "    test_blocks = 1,\n",
    "    param_grid = hyperparams_grid,\n",
    "    verbose = 0)\n",
    "\n",
    "    # Run the model for NLP scenario\n",
    "    final_results_nlp = walk_forward_block_optimization(\n",
    "    X = X_nlp,\n",
    "    y = y_nlp,\n",
    "    n_blocks = 15,\n",
    "    train_blocks = 10,\n",
    "    val_blocks = 1,\n",
    "    test_blocks = 1,\n",
    "    param_grid = hyperparams_grid,\n",
    "    verbose = 0)\n",
    "\n",
    "    # Store results\n",
    "    results.append([ticker, final_results_base, final_results_nlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_trading_hour(idx):\n",
    "    \"\"\"\n",
    "    Return True if timestamp idx is a weekday (Mon-Fri) between 09:30 and 16:30.\n",
    "    Otherwise False.\n",
    "    \"\"\"\n",
    "    # idx is a pandas Timestamp\n",
    "    if idx.weekday() >= 5:  # 5=Saturday,6=Sunday => market closed\n",
    "        return False\n",
    "    # Check time of day\n",
    "    if idx.time() < datetime.time(9, 30) or idx.time() >= datetime.time(16, 30):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def sign_func(x, threshold=0.0):\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    elif x < -threshold:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def backtest_equity_with_mask(df):\n",
    "\n",
    "    # Get data\n",
    "    df = df.copy()\n",
    "    df['actual_return'] = df['true_value'].pct_change()\n",
    "    df['pred_return'] = df['predicted_value'].pct_change()\n",
    "\n",
    "    # Generate all signals and map trading hours\n",
    "    df['signal'] = df['pred_return'].apply(sign_func)\n",
    "    df['in_market'] = df.index.map(is_trading_hour).astype(int)  \n",
    "\n",
    "    # Calculate returns\n",
    "    df['signal'] = df['signal'] * df['in_market']  \n",
    "    df['strategy_return'] = df['signal'].shift(1) * df['actual_return']\n",
    "\n",
    "    # Calculate equity curve\n",
    "    df['strategy_equity'] = (1 + df['strategy_return'].fillna(0)).cumprod()\n",
    "    df['buy_and_hold']    = (1 + df['actual_return'].fillna(0)).cumprod()\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSTS = 0.0\n",
    "\n",
    "def backtest_long_only(df: pd.DataFrame, cost_rate: float = COSTS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Compute actual_return, pred_return\n",
    "    2) Convert pred_return -> raw_signal = {+1,0,-1} via sign_func\n",
    "    3) For 'long only', we set negative signals to 0 => final_signal = max(raw_signal, 0)\n",
    "    4) Zero out signals if outside trading hours\n",
    "    5) strategy_return[t] = signal[t-1] * actual_return[t] - transaction_cost\n",
    "    6) Build equity curves\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Compute returns\n",
    "    df['actual_return'] = df['true_value'].pct_change()\n",
    "    df['pred_return']   = df['predicted_value'].pct_change()\n",
    "\n",
    "    # 2) Raw signal\n",
    "    df['raw_signal'] = df['pred_return'].apply(sign_func)\n",
    "\n",
    "    # 3) Long only => if raw_signal < 1 => 0\n",
    "    df['signal'] = df['raw_signal'].clip(lower=0)\n",
    "\n",
    "    # 4) Zero-out signals outside market hours\n",
    "    df['in_market'] = df.index.map(is_trading_hour).astype(int)\n",
    "    df['signal'] = df['signal'] * df['in_market']\n",
    "\n",
    "    # 5) Strategy return\n",
    "    #    - shift the signal by 1 so position[t-1] is applied to actual_return[t]\n",
    "    df['strategy_return'] = df['signal'].shift(1) * df['actual_return']\n",
    "\n",
    "    # Transaction cost (simplified):\n",
    "    # cost_rate * abs(pos_change)\n",
    "    df['pos_change'] = df['signal'].diff().fillna(df['signal'])\n",
    "    df['transaction_cost'] = cost_rate * df['pos_change'].abs()\n",
    "    df['strategy_return'] = df['strategy_return'] - df['transaction_cost'].fillna(0)\n",
    "\n",
    "    # 6) Equity curves\n",
    "    df['strategy_equity'] = (1 + df['strategy_return'].fillna(0)).cumprod()\n",
    "    df['buy_and_hold']    = (1 + df['actual_return'].fillna(0)).cumprod()\n",
    "\n",
    "    return df\n",
    "\n",
    "def backtest_leveraged_long_only(df: pd.DataFrame, cost_rate: float = COSTS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Similar to backtest_long_only, but consecutive +1 signals => keep adding more.\n",
    "    The moment the signal is not +1, we go flat (position=0).\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Compute returns\n",
    "    df['actual_return'] = df['true_value'].pct_change()\n",
    "    df['pred_return']   = df['predicted_value'].pct_change()\n",
    "\n",
    "    # 2) raw signal => +1/0/-1\n",
    "    df['raw_signal'] = df['pred_return'].apply(sign_func)\n",
    "\n",
    "    # 3) Build 'signal' in a loop:\n",
    "    #    - if raw_signal[t] == +1, position[t] = position[t-1] + 1\n",
    "    #    - else 0\n",
    "    position = 0\n",
    "    sig_array = []\n",
    "    for t in range(len(df)):\n",
    "        val = df['raw_signal'].iloc[t]\n",
    "        if val == 1:\n",
    "            position += 1\n",
    "        else:\n",
    "            position = 0\n",
    "        sig_array.append(position)\n",
    "\n",
    "    df['signal'] = sig_array\n",
    "\n",
    "    # 4) Zero out if outside market hours\n",
    "    df['in_market'] = df.index.map(is_trading_hour).astype(int)\n",
    "    df['signal'] = df['signal'] * df['in_market']\n",
    "\n",
    "    # 5) Strategy return\n",
    "    df['strategy_return'] = df['signal'].shift(1) * df['actual_return']\n",
    "\n",
    "    # Transaction cost\n",
    "    df['pos_change'] = df['signal'].diff().fillna(df['signal'])\n",
    "    df['transaction_cost'] = cost_rate * df['pos_change'].abs()\n",
    "    df['strategy_return'] = df['strategy_return'] - df['transaction_cost'].fillna(0)\n",
    "\n",
    "    # 6) Equity curves\n",
    "    df['strategy_equity'] = (1 + df['strategy_return'].fillna(0)).cumprod()\n",
    "    df['buy_and_hold']    = (1 + df['actual_return'].fillna(0)).cumprod()\n",
    "\n",
    "    return df\n",
    "\n",
    "def backtest_both_ways(df: pd.DataFrame, cost_rate: float = COSTS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Both ways (one lot):\n",
    "      - raw_signal=+1 => position=+1\n",
    "      - raw_signal=-1 => position=-1\n",
    "      - raw_signal= 0 => position=0\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) returns\n",
    "    df['actual_return'] = df['true_value'].pct_change()\n",
    "    df['pred_return']   = df['predicted_value'].pct_change()\n",
    "\n",
    "    # 2) raw_signal => +1/-1/0\n",
    "    df['raw_signal'] = df['pred_return'].apply(sign_func)\n",
    "\n",
    "    # 3) Final signal => same as raw_signal, but ensure it's only -1,0,+1\n",
    "    #    (sign_func already ensures that)\n",
    "    df['signal'] = df['raw_signal']\n",
    "\n",
    "    # 4) Zero out if outside hours\n",
    "    df['in_market'] = df.index.map(is_trading_hour).astype(int)\n",
    "    df['signal'] = df['signal'] * df['in_market']\n",
    "\n",
    "    # 5) Strategy return\n",
    "    df['strategy_return'] = df['signal'].shift(1) * df['actual_return']\n",
    "\n",
    "    # cost\n",
    "    df['pos_change'] = df['signal'].diff().fillna(df['signal'])\n",
    "    df['transaction_cost'] = cost_rate * df['pos_change'].abs()\n",
    "    df['strategy_return'] = df['strategy_return'] - df['transaction_cost'].fillna(0)\n",
    "\n",
    "    # 6) equity\n",
    "    df['strategy_equity'] = (1 + df['strategy_return'].fillna(0)).cumprod()\n",
    "    df['buy_and_hold']    = (1 + df['actual_return'].fillna(0)).cumprod()\n",
    "\n",
    "    return df\n",
    "\n",
    "def backtest_both_ways_leveraged(df: pd.DataFrame, cost_rate: float = COSTS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Both ways leveraged:\n",
    "      - If raw_signal[t]==+1 repeatedly => accumulate +1 each bar\n",
    "      - If raw_signal[t]==-1 repeatedly => accumulate -1 each bar\n",
    "      - Flip from + to - => close out all (pos=0), then open -1\n",
    "      - Flip from - to + => close out all (pos=0), then open +1\n",
    "      - raw_signal=0 => go flat\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) returns\n",
    "    df['actual_return'] = df['true_value'].pct_change()\n",
    "    df['pred_return']   = df['predicted_value'].pct_change()\n",
    "\n",
    "    # 2) raw_signal => +1/0/-1\n",
    "    df['raw_signal'] = df['pred_return'].apply(sign_func)\n",
    "\n",
    "    # 3) Build 'signal' in a loop\n",
    "    position = 0\n",
    "    final_sig = []\n",
    "    for t in range(len(df)):\n",
    "        s = df['raw_signal'].iloc[t]\n",
    "        if s > 0:  # +1\n",
    "            if position >= 0:\n",
    "                # keep adding +1\n",
    "                position += 1\n",
    "            else:\n",
    "                # we were negative, close out\n",
    "                position = 1\n",
    "        elif s < 0:  # -1\n",
    "            if position <= 0:\n",
    "                # keep adding -1\n",
    "                position -= 1\n",
    "            else:\n",
    "                # we were positive, close out\n",
    "                position = -1\n",
    "        else:\n",
    "            # s=0 => go flat\n",
    "            position = 0\n",
    "        final_sig.append(position)\n",
    "\n",
    "    df['signal'] = final_sig\n",
    "\n",
    "    # 4) zero out if outside market hours\n",
    "    df['in_market'] = df.index.map(is_trading_hour).astype(int)\n",
    "    df['signal'] = df['signal'] * df['in_market']\n",
    "\n",
    "    # 5) strategy_return\n",
    "    df['strategy_return'] = df['signal'].shift(1) * df['actual_return']\n",
    "\n",
    "    # cost\n",
    "    df['pos_change'] = df['signal'].diff().fillna(df['signal'])\n",
    "    df['transaction_cost'] = cost_rate * df['pos_change'].abs()\n",
    "    df['strategy_return'] = df['strategy_return'] - df['transaction_cost'].fillna(0)\n",
    "\n",
    "    # 6) equity\n",
    "    df['strategy_equity'] = (1 + df['strategy_return'].fillna(0)).cumprod()\n",
    "    df['buy_and_hold']    = (1 + df['actual_return'].fillna(0)).cumprod()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to store all backtests\n",
    "combined = backtest_long_only(results[0][1]).copy()\n",
    "combined = combined[['buy_and_hold']]\n",
    "\n",
    "for iter in range(len(results)):\n",
    "\n",
    "    # Get ticker name\n",
    "    ticker = results[iter][0]\n",
    "\n",
    "    # Get model outputs\n",
    "    base, nlp = results[iter][1], results[iter][2]\n",
    "\n",
    "    # Collect all models\n",
    "\n",
    "    combined[f'Long_only_base_{ticker}'] = backtest_long_only(base)['strategy_equity']\n",
    "    combined[f'Long_only_nlp_{ticker}'] = backtest_long_only(nlp)['strategy_equity']\n",
    "\n",
    "    combined[f'leveraged_long_only_base_{ticker}'] = backtest_leveraged_long_only(base)['strategy_equity']\n",
    "    combined[f'leveraged_long_only_nlp_{ticker}'] = backtest_leveraged_long_only(nlp)['strategy_equity']\n",
    "\n",
    "    combined[f'Both_ways_base_{ticker}'] = backtest_both_ways(base)['strategy_equity']\n",
    "    combined[f'Both_ways_nlp_{ticker}'] = backtest_both_ways(nlp)['strategy_equity']\n",
    "\n",
    "    combined[f'both_ways_leveraged_base_{ticker}'] = backtest_both_ways_leveraged(base)['strategy_equity']\n",
    "    combined[f'both_ways_leveraged_nlp_{ticker}'] = backtest_both_ways_leveraged(nlp)['strategy_equity']\n",
    "\n",
    "combined['final_leveraged_long_only_base'] = combined[[elem for elem in combined.columns if 'leveraged_long_only_base' in elem]].mean(axis = 1)\n",
    "combined['final_Long_only_base'] = combined[[elem for elem in combined.columns if 'Long_only_base' in elem]].mean(axis = 1)\n",
    "combined['final_both_ways_leveraged_base'] = combined[[elem for elem in combined.columns if 'both_ways_leveraged_base' in elem]].mean(axis = 1)\n",
    "combined['final_Both_ways_base'] = combined[[elem for elem in combined.columns if 'Both_ways_base' in elem]].mean(axis = 1)\n",
    "\n",
    "combined['final_leveraged_long_only_nlp'] = combined[[elem for elem in combined.columns if 'leveraged_long_only_nlp' in elem]].mean(axis = 1)\n",
    "combined['final_Long_only_nlp'] = combined[[elem for elem in combined.columns if 'Long_only_nlp' in elem]].mean(axis = 1)\n",
    "combined['final_both_ways_leveraged_nlp'] = combined[[elem for elem in combined.columns if 'both_ways_leveraged_nlp' in elem]].mean(axis = 1)\n",
    "combined['final_Both_ways_nlp'] = combined[[elem for elem in combined.columns if 'Both_ways_nlp' in elem]].mean(axis = 1)\n",
    "\n",
    "combined['final_BH'] = combined['buy_and_hold']\n",
    "combined = combined[[elem for elem in combined.columns if 'final_' in elem]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basket of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(combined):\n",
    "    # Example color palettes (4 shades of green, 4 shades of blue)\n",
    "    green_shades = ['limegreen', 'forestgreen', 'seagreen', 'darkgreen']\n",
    "    blue_shades  = ['dodgerblue', 'royalblue', 'cornflowerblue', 'navy']\n",
    "\n",
    "    # The \"base names\" of your strategies in the DataFrame columns\n",
    "    strategies = [\n",
    "        'Long_only',\n",
    "        'leveraged_long_only',\n",
    "        'Both_ways',\n",
    "        'both_ways_leveraged'\n",
    "    ]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    for i, st in enumerate(strategies):\n",
    "        # 1) \"base\" version => pick a green color\n",
    "        col_base = f'final_{st}_base'\n",
    "        ax1.plot(\n",
    "            combined[col_base], \n",
    "            label=f'{st}_base',\n",
    "            color=green_shades[i]\n",
    "        )\n",
    "\n",
    "        # 2) \"nlp\" version => pick a blue color\n",
    "        col_nlp = f'final_{st}_nlp'\n",
    "        ax1.plot(\n",
    "            combined[col_nlp], \n",
    "            label=f'{st}_nlp',\n",
    "            color=blue_shades[i]\n",
    "        )\n",
    "\n",
    "    ax1.plot(combined['final_BH'], label = 'Buy And Hold', color = 'red')\n",
    "\n",
    "    ax1.set_title('Comparison of B&H, LSTM_NLP and LSTM_Base')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaximumDrawdown(equity, text = \"\"):\n",
    "\n",
    "    # Drawdown calculation\n",
    "    equity['drawdowns'] = 1 - equity[text]/(equity[text].cummax())\n",
    "    max_drawdown = equity['drawdowns'].max()\n",
    "    start_index = equity['drawdowns'].idxmax()\n",
    "    start_index = equity[text].loc[:start_index].idxmax()\n",
    "    \n",
    "    # Find the level of equity at the start of the drawdown\n",
    "    start_equity_level = equity[text].loc[start_index]\n",
    "    \n",
    "    # Search for the index where equity returns to a level higher than or equal to the level at the start of the drawdown\n",
    "    equity = equity.loc[start_index:]\n",
    "    end_index = equity[text][equity[text] > start_equity_level].index.min()\n",
    "\n",
    "    if str(start_index) == 'NaT':\n",
    "        start_index = equity.index[0]\n",
    "    if str(end_index) == 'NaT':\n",
    "        end_index = equity.index[-1]\n",
    "\n",
    "\n",
    "    return max_drawdown, start_index, end_index\n",
    "\n",
    "def PerformanceMetrics(df, fix = 'base'):\n",
    "\n",
    "    # Data\n",
    "    equity = df.copy()\n",
    "    equity = equity[[fix]]\n",
    "    equity['Daily_return'] = equity[fix].pct_change()\n",
    "    equity = equity.dropna()\n",
    "\n",
    "    # ARC\n",
    "    ARC = (equity[fix].values[-1])**(252/(len(equity)/24)) - 1\n",
    "    \n",
    "\n",
    "    # aSD\n",
    "    aSD = (equity[f'Daily_return'].std()) * (np.sqrt(252))\n",
    "    \n",
    "\n",
    "    # Maximum Drawdown and Maximum Drawdown Duration\n",
    "    MD, start_drawdown, end_drawdown = MaximumDrawdown(equity, fix)\n",
    "    MLD = np.abs((end_drawdown - start_drawdown).days)/252.03\n",
    "\n",
    "    # Information Ratio *\n",
    "    IR1 = ARC/aSD\n",
    "\n",
    "    # Information Ratio **\n",
    "    IR2 = ARC**3/(aSD*ARC*MD)\n",
    "\n",
    "    # Information Ratio ***\n",
    "    IR3 = ARC**3/(aSD*MD*MLD)\n",
    "\n",
    "    #print(f'ARC = {round(100*ARC, 3)}% aSD = {round(aSD, 5)} MD = {round(100*MD, 3)}% MLD = {round(MLD, 3)}yrs IR1 = {round(IR1, 3)} IR2 = {round(IR2, 3)} IR3 = {round(IR3, 3)}')\n",
    "\n",
    "    metrics = {\n",
    "        'name' : fix,\n",
    "        'ARC': 100 * ARC,\n",
    "        'aSD': aSD,\n",
    "        'MD': 100 * MD,\n",
    "        'MLD': MLD,\n",
    "        'IR1': IR1,\n",
    "        'IR2': IR2,\n",
    "        'IR3': IR3\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def PerformanceMetricsTable(combined):\n",
    "\n",
    "    performance_metrics_table = pd.concat(\n",
    "    [pd.DataFrame(PerformanceMetrics(combined, fix), index = list(range(1)))\n",
    "     for fix in combined.columns])\n",
    "\n",
    "    performance_metrics_table.index = performance_metrics_table['name']\n",
    "    performance_metrics_table = performance_metrics_table[['ARC', 'aSD', 'MD', 'MLD', 'IR1', 'IR2', 'IR3']]\n",
    "    performance_metrics_table\n",
    "\n",
    "    return performance_metrics_table.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PerformanceMetricsTable(combined)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
