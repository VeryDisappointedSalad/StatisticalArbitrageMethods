{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NVDA...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for AMD...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for INTC...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for TSM...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for QCOM...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for TXN...\n",
      "Fetching data for AVGO...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for MU...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for ASML...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Fetching data for MRVL...\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Data saved to microprocessor_stocks_2023-25.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "API_KEY = \"o9MHKBamfGm9xCIxiLlbUPDwCWmjdWk4\"\n",
    "\n",
    "def download_historical_data(ticker, start_date, end_date, timespan=\"day\", retries=3):\n",
    "    \"\"\"\n",
    "    Downloads historical data from Polygon.io for backtesting with retries and pagination.\n",
    "\n",
    "    :param ticker: Stock ticker symbol (e.g., \"NVDA\").\n",
    "    :param start_date: Start date in the format \"YYYY-MM-DD\".\n",
    "    :param end_date: End date in the format \"YYYY-MM-DD\".\n",
    "    :param timespan: Timespan of data (\"minute\", \"hour\", \"day\").\n",
    "    :param retries: Number of retries in case of API failure.\n",
    "    :return: Pandas DataFrame containing the historical data or None if no data is found.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/{timespan}/{start_date}/{end_date}\"\n",
    "    params = {\"apiKey\": API_KEY, \"limit\": 50000}  \n",
    "    all_data = []\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            while url:\n",
    "                response = requests.get(url, params=params)\n",
    "                \n",
    "                \n",
    "                if response.status_code == 429:  \n",
    "                    print(f\"Rate limit reached. Waiting before retrying...\")\n",
    "                    time.sleep(60)  # Wait 60 seconds before retrying due to potential rate limiting\n",
    "                    continue\n",
    "                \n",
    "                response.raise_for_status()  \n",
    "                \n",
    "                data = response.json()\n",
    "                if \"results\" in data and data[\"results\"]:\n",
    "                    all_data.extend(data[\"results\"])\n",
    "                \n",
    "                # Check for \"next_url\" to continue pagination\n",
    "                url = data.get(\"next_url\", None)\n",
    "\n",
    "            # Break if data is fetched successfully\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {ticker}: {e}\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    if not all_data:\n",
    "        print(f\"No data found for {ticker}.\")\n",
    "        return None\n",
    "\n",
    "   \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"t\"], unit=\"ms\")  \n",
    "    df = df.rename(columns={\"o\": \"open\", \"h\": \"high\", \"l\": \"low\", \"c\": \"close\", \"v\": \"volume\"})\n",
    "    df = df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "    df[\"ticker\"] = ticker  \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_combined_data(tickers, start_date, end_date, timespan=\"day\", output_file=\"microprocessor_stocks.csv\"):\n",
    "    \"\"\"\n",
    "    Downloads and combines historical data for multiple tickers and saves it to a single CSV file.\n",
    "    \n",
    "    :param tickers: List of stock ticker symbols.\n",
    "    :param start_date: Start date in the format \"YYYY-MM-DD\".\n",
    "    :param end_date: End date in the format \"YYYY-MM-DD\".\n",
    "    :param timespan: Timespan of data (\"minute\", \"hour\", \"day\").\n",
    "    :param output_file: Name of the output CSV file.\n",
    "    \"\"\"\n",
    "    all_data = [] \n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        df = download_historical_data(ticker, start_date, end_date, timespan)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "        \n",
    "        # Adding a delay to respect API rate limits\n",
    "        time.sleep(15) \n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No data was fetched. No file created.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Names of the companies whose stocks will be used for the analysis\n",
    "    tickers = [\n",
    "        \"NVDA\",  # NVIDIA\n",
    "        \"AMD\",   # Advanced Micro Devices\n",
    "        \"INTC\",  # Intel Corporation\n",
    "        \"TSM\",   # Taiwan Semiconductor\n",
    "        \"QCOM\",  # Qualcomm\n",
    "        \"TXN\",   # Texas Instruments\n",
    "        \"AVGO\",  # Broadcom\n",
    "        \"MU\",    # Micron Technology\n",
    "        \"ASML\",  # ASML Holding\n",
    "        \"MRVL\"   # Marvell Technology\n",
    "    ]\n",
    "    \n",
    "    #Date range for backtesting\n",
    "    start_date = \"2023-02-01\"\n",
    "    end_date = \"2025-01-18\"\n",
    "    \n",
    "    #Minute frequency of the data\n",
    "    timespan = \"minute\"\n",
    "    \n",
    "  \n",
    "    output_file = \"microprocessor_stocks_2023-25.csv\"\n",
    "    \n",
    "    \n",
    "    save_combined_data(tickers, start_date, end_date, timespan, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
