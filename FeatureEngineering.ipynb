{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Data/Real/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ind = 0, # which of the file\n",
    "              type = 'Financial/',  # type = ['Text', 'Financial']\n",
    "              ):\n",
    "    \n",
    "    assert ind < len(os.listdir(PATH + type)) , f'Chose {ind + 1}. file out of *{len(os.listdir(PATH + type))}* files'\n",
    "    print(f'Loading {os.listdir(PATH + type)[ind]}')\n",
    "    return pd.read_csv(PATH + type + os.listdir(PATH + type)[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and get tickers\n",
    "X_financial = load_data(1, type = 'Financial/')\n",
    "\n",
    "TICKERS = X_financial['ticker'].unique()\n",
    "TICKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_financial['timestamp'] = pd.to_datetime(X_financial['timestamp'])\n",
    "X_financial = X_financial[['close', 'volume', 'ticker']]\n",
    "\n",
    "X_financial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose start and end date for financial data so that is starts and ends in the spot for all available tickers\n",
    "start_date = max([X_financial[X_financial['ticker'] == t].index[0] for t in X_financial['ticker'].unique()])\n",
    "end_date   = max([X_financial[X_financial['ticker'] == t].index[-1] for t in X_financial['ticker'].unique()])\n",
    "\n",
    "X_financial = X_financial.loc[X_financial.index >= start_date]\n",
    "X_financial = X_financial.loc[X_financial.index <= end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available tickers to invest (from the financial .csv) one are\n",
    "TICKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_string):\n",
    "    date_obj = datetime.strptime(date_string, \"%a, %d %b %Y %H:%M:%S %z\")\n",
    "    # Replace with the desired date and time\n",
    "    return date_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Load the data\n",
    "X_text = pd.concat(\n",
    "    [load_data(j, type = 'Text/')[['text', 'date', 'sentiment', 'tickers']] for j in range(14)],\n",
    "    axis = 0\n",
    ")\n",
    "\n",
    "# Choose only rows with at least one ticker mentioning some ticker in TICKERS\n",
    "filtered_rows = X_text[X_text['tickers'].apply(lambda x: not set(eval(x)).isdisjoint(TICKERS))].copy()\n",
    "filtered_rows['tickers'] = filtered_rows['tickers'].apply(lambda x: [ticker for ticker in eval(x) if ticker in TICKERS])\n",
    "\n",
    "# Choose only important columns\n",
    "filtered_rows = filtered_rows[['text', 'date', 'sentiment', 'tickers']]\n",
    "\n",
    "# Format the date\n",
    "filtered_rows['date'] = filtered_rows['date'].apply(convert_date)\n",
    "\n",
    "# Bool columns for TICKERS\n",
    "for ticker in TICKERS:\n",
    "    filtered_rows[f'bool_{ticker}'] = filtered_rows['tickers'].apply(lambda x : ticker in x)\n",
    "\n",
    "# Round *up* the date to a full minute\n",
    "filtered_rows['date'] = pd.to_datetime(filtered_rows['date'])\n",
    "filtered_rows['date'] = filtered_rows['date'].dt.ceil('min')\n",
    "\n",
    "# Compute VADER sentiment scores\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "filtered_rows['score'] = filtered_rows['text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Sort by date\n",
    "filtered_rows = filtered_rows.sort_values(by = 'date', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = filtered_rows.melt(\n",
    "    id_vars=['date', 'score', 'sentiment'], \n",
    "    value_vars=[f'bool_{ticker}' for ticker in TICKERS], \n",
    "    var_name='ticker', \n",
    "    value_name='is_present'\n",
    ")\n",
    "\n",
    "melted = melted[melted['is_present']]\n",
    "\n",
    "melted['ticker'] = melted['ticker'].str.replace('bool_', '')\n",
    "\n",
    "combined = melted.pivot_table(\n",
    "    index='date',\n",
    "    columns='ticker',\n",
    "    values=['score', 'sentiment'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "combined.columns = [f\"{col[1]}_{col[0]}\" for col in combined.columns]\n",
    "\n",
    "combined = combined.reset_index().sort_values(by='date')\n",
    "combined.ffill(inplace=True)\n",
    "\n",
    "for col in combined.columns:\n",
    "\n",
    "    if '_sentiment' in col:\n",
    "        combined[col] = combined[col].astype('string').fillna('Neutral')\n",
    "    elif '_score' in col:\n",
    "        combined[col] = combined[col].fillna(0)\n",
    "\n",
    "\n",
    "# Ffill() wrt. the date column in minute frequency\n",
    "combined['date'] = pd.to_datetime(combined['date'])\n",
    "combined = combined.set_index(combined['date']).sort_index()\n",
    "combined = combined.resample('1min').ffill()\n",
    "\n",
    "# Outcome of hard work\n",
    "X_nlp = combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_financial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the dates on `X_financial` and `X_nlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_financial = X_financial[X_financial['ticker'] == TICKERS[0]].copy()\n",
    "temp_financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for t in TICKERS:\n",
    "    temp_financial = X_financial[X_financial['ticker'] == t].copy()\n",
    "    temp_nlp = X_nlp[[f'{t}_score', f'{t}_sentiment']].copy()\n",
    "\n",
    "    # Choose correct dates\n",
    "    start_date = max(temp_financial.index[0], temp_nlp.index[0])\n",
    "    end_date = min(temp_financial.index[-1], temp_nlp.index[-1])\n",
    "\n",
    "    # Set dates in both dfs\n",
    "    temp_financial = temp_financial.loc[temp_financial.index >= start_date]\n",
    "    temp_financial = temp_financial.loc[temp_financial.index <= end_date]\n",
    "\n",
    "    temp_nlp = temp_nlp.loc[temp_nlp.index >= start_date]\n",
    "    temp_nlp = temp_nlp.loc[temp_nlp.index <= end_date]\n",
    "\n",
    "    temp_financial = temp_financial.resample('1min').ffill()\n",
    "    temp_nlp = temp_nlp.resample('1min').ffill()\n",
    "\n",
    "\n",
    "    temp = pd.concat([temp_financial, temp_nlp], axis = 1)\n",
    "    all_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good start for all\n",
    "start_date = max([temp.index[0] for temp in all_data])\n",
    "end_date = min([temp.index[-1] for temp in all_data])\n",
    "\n",
    "all_data = [\n",
    "    temp.loc[(temp.index >=start_date) & (temp.index <= end_date)]\n",
    "    for temp in all_data\n",
    "]\n",
    "\n",
    "iter = 0\n",
    "for temp in all_data:\n",
    "    start_date = temp.index[0]\n",
    "    end_date = temp.index[-1]\n",
    "    temp.to_csv(f'Data/ParsedDataForModel/{TICKERS[iter]}.csv')\n",
    "    print(f'Managed to save {TICKERS[iter]}.csv. Start date {start_date}, End date {end_date}')\n",
    "    iter = iter + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
